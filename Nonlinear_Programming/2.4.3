Question 2.4.3 (Computational Problem)

Function: f(y,z) = (1/2)*sum_1_n[ (z_i - phi(u1*y_i-u0))^2 ]

Sigmoidal Function: phi(eta) = 1/(1+e^-eta)

Data pairs: (y,z) = (1.165,1), (0.626,-1), (0.075,-1), (0.351,1), (-0.696,1)

The constants (u0,u1)=(0,1)

********
A function minimization is possible and an answer. An alternative solution provides an average step for the each data point. Lastly, a third solution extrapolates the difference about the previous two solutions for error. 
********* 

Gauss-Newton Method:
        
       A minimized function in y- and z-directions:

           y^{k+1} = y^k - f(z,y^k)*delf(y^k)/del[delf(y^k)]
       
                   = y^k - f(z,y^k)*(e^y+1)*((e^y+1)z-e^y)/(-e^{2y}(z-1)-2*e^y+z)


           z^{k+1} = z^k - f(y,z^k)*delf(z^k)/del[delf(z^k)]
 
                   = z^k - f(y,z^k)

       Average change per k-step:

           df(y,z)/dy = d/dy[(1/2)*(z - phi(u1*y-u0))^2 

                      = -u1*e^{u1*y+u0}*((z_i*(e^{u1*y}+e^u0)-e^{u1*y}))/(e^{u1*y}+e^u0)^3

                      = e^{y_i}*(z*(e^{y}+1)-e^y)/(e^{y}+1)^3
 
           d/dy[df(y,z)/dy] = (e^y+1)*((e^y+1)z-e^y)/(-e^{2y}(z-1)-2*e^y+z)

           df(y,z)/dz = d/dz[(1/2)*[ z - phi(u1*y-u0))^2 ]] 

                      = z_i-phi(u1*y-u0]
  
           d/dz[df(y,z)/dz] = 1         

       Error between continuous and discrete minimization:

           Change in the y-direction:                    
 
                      Continuous        Discrete         Difference
           Step #1:      1.50             
           Step #2:      1.96
           Step #3:      2.43
           Step #4:      2.91
           Step #5:      3.40

           Change in the z-direction:                    

                      Continuous        Discrete         Difference
           Step #1:      0.57
           Step #2:      0.61
           Step #3:      0.63
           Step #4:      0.65
           Step #5:      0.66
 
Something is odd in the problem because the original equation for Figure 1.4.3 already answers itself by summation.

Extended Kalman Filter:

Incremental Gradient Method:



Incremental Aggregated Gradient Method:


        
Rules Gauss-Newton Method:
        x^{k+1} = x^k - f(x)*delf(x^k)/del[delf(x)]
      
      Extended Kalman Filter:
        x^{k+1} = x^k - sum_1_n[delg*g]/H
        H = sum_0_k[sum_1_n[delg*g]]     
 
      Incremental Gradient Method:
       x^{k+1} = x^k - alpha^k*delf_i(x^k)
      
      Incremental Aggregated Gradient Method:
       x^{k+1} = x^k - alpha^k*sum_0_m-1 [delf(x^{k-l}]
